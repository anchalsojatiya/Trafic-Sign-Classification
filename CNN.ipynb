{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading necessary libraraies\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import normalize\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>ShapeId</th>\n",
       "      <th>ColorId</th>\n",
       "      <th>SignId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Meta/27.png</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Meta/0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Meta/1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Meta/10.png</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Meta/11.png</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path  ClassId  ShapeId  ColorId SignId\n",
       "0  Meta/27.png       27        0        0   1.32\n",
       "1   Meta/0.png        0        1        0   3.29\n",
       "2   Meta/1.png        1        1        0   3.29\n",
       "3  Meta/10.png       10        1        0   3.27\n",
       "4  Meta/11.png       11        0        0   1.22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "train = pd.read_csv('Train.csv')\n",
    "train.head()\n",
    "test = pd.read_csv('Test.csv')\n",
    "test.head()\n",
    "meta_data = pd.read_csv('Meta.csv')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading train images to numpy array\n",
    "random.seed(123 )\n",
    "train_x=[]\n",
    "for i in train['Path']:\n",
    "    try:\n",
    "        img = Image.fromarray(cv2.imread(i), 'RGB') #reading image\n",
    "        train_x.append(np.array(img.resize((32, 32)))) #converting to numpy and append to list\n",
    "    except AttributeError:\n",
    "        print(\"Error in loading image\")\n",
    "\n",
    "\n",
    "train_x=np.array(train_x)\n",
    "train_y = np.array(train['ClassId'].values) #storing class labels in list\n",
    "train_x.astype(float)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12630, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading test images to numpy array\n",
    "random.seed(123)\n",
    "test_x=[]\n",
    "for i in test['Path']:\n",
    "    try:\n",
    "        img = Image.fromarray(cv2.imread(i), 'RGB') #reading image\n",
    "        test_x.append(np.array(img.resize((32, 32)))) #converting to numpy and append to list\n",
    "    except AttributeError:\n",
    "        print(\"Error in loading image\")\n",
    "\n",
    "\n",
    "\n",
    "test_x=np.array(test_x)\n",
    "test_y = np.array(test['ClassId'].values)  #storing class labels in list\n",
    "test_x.astype(float)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "train_x_min = train_x.min(axis=(0, 1), keepdims=True)\n",
    "train_x_max = train_x.max(axis=(0, 1), keepdims=True)\n",
    "train_x=(train_x - train_x_min)/(train_x_max - train_x_min)\n",
    "\n",
    "test_x_min = test_x.min(axis=(0, 1), keepdims=True)\n",
    "test_x_max = test_x.max(axis=(0, 1), keepdims=True)\n",
    "test_x=(test_x - test_x_min)/(test_x_max - test_x_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "\n",
    "tensor_x = torch.Tensor(train_x)\n",
    "# converting from tensor batch-height-width-channel dimenssion to \n",
    "# pytorch tensor expected dimension batch-channel-height-width\n",
    "tensor_x=tensor_x.permute(0, 3, 1, 2)\n",
    "tensor_y = torch.Tensor(train_y)\n",
    "tensor_x_test = torch.Tensor(test_x) \n",
    "tensor_x_test=tensor_x_test.permute(0, 3, 1, 2)\n",
    "tensor_y_test = torch.Tensor(test_y)\n",
    "\n",
    "my_dataset_x = data.TensorDataset(tensor_x) # create your datset\n",
    "my_dataset_y = data.TensorDataset(tensor_y) # create your datset\n",
    "my_dataset_x_test = data.TensorDataset(tensor_x_test) # create your datset\n",
    "my_dataset_y_test = data.TensorDataset(tensor_y_test) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39209, 3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "trainloader_x = torch.utils.data.DataLoader(my_dataset_x)\n",
    "trainloader_y = torch.utils.data.DataLoader(my_dataset_y)\n",
    "testloader_x = torch.utils.data.DataLoader(my_dataset_x_test)\n",
    "testloader_y = torch.utils.data.DataLoader(my_dataset_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.dropout2 = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(1 * 48 * 48, 256)\n",
    "        self.fc2 = nn.Linear(256, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(-1,1 * 48 * 48)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = UNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Train Accuracy: 95.94% , Test Accuracy:  0.71%\n",
      "Epoch [2/5],Train Accuracy: 96.36% , Test Accuracy:  0.71%\n",
      "Epoch [3/5],Train Accuracy: 96.78% , Test Accuracy:  0.71%\n",
      "Epoch [4/5],Train Accuracy: 97.11% , Test Accuracy:  0.71%\n",
      "Epoch [5/5],Train Accuracy: 97.34% , Test Accuracy:  0.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2064e00a288>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(100)\n",
    "num_epochs=5\n",
    "train_accuracy=[]\n",
    "test_accuracy=[]\n",
    "epochs=[]\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i, (data, data2) in enumerate(zip(trainloader_x,trainloader_y), 0):\n",
    "        \n",
    "        # get the inputs and labels\n",
    "        inputs= data[0][0]\n",
    "        labels=data2[0].type(torch.LongTensor)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs[None,...])\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Calculate train accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.nelement()\n",
    "        correct_train += predicted.eq(labels.data).sum().item()\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for i,(data_test, data2_test) in enumerate(zip(testloader_x,testloader_y),0):\n",
    "            test_inputs= data_test[0][0]\n",
    "            test_labels=data2_test[0].type(torch.LongTensor)\n",
    "            outputs_test = net(test_inputs[None,...])\n",
    "            \n",
    "             #Calculate test accuracy\n",
    "            _, predicted_test = torch.max(outputs_test.data, 1)\n",
    "            total_test += test_labels.nelement()\n",
    "            correct_test += predicted_test.eq(test_labels.data).sum().item()\n",
    "            test_acc = 100 * correct_test / total_test\n",
    "        \n",
    "    train_accuracy.append(train_acc)    \n",
    "    epochs.append(epoch)         \n",
    "    test_accuracy.append(test_acc)    \n",
    "    print('Epoch [{}/{}],Train Accuracy: {:.2f}% , Test Accuracy:  {:.2f}%'\n",
    "        .format(epoch + 1, num_epochs,\n",
    "                train_acc,test_acc))\n",
    "    \n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(test_accuracy, label='Test Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test overall accuracy of the model\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,(data, data2) in enumerate(zip(testloader_x,testloader_y),0):\n",
    "        inputs= data[0][0]\n",
    "        labels=data2[0].type(torch.LongTensor)\n",
    "        \n",
    "        outputs = net(inputs[None,...])\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.nelement()\n",
    "        correct += predicted.eq(labels.data).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on  test images: {} %'.format((correct / total) * 100))\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
